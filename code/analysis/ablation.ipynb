{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析normalzation操作的必要性和rescale操作的必要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验1，取消norm操作和rescale操作\n",
    "# 当前只考虑filter_0_bias_token的情况\n",
    "import json\n",
    "# 统计原始结果\n",
    "prompts = [\"LAMA\",\"LPAQA\",\"AutoPrompt\",\"optiprompt\"]\n",
    "models = [\"bert-base-cased\",\"bert-large-cased\",\"roberta-large\"]\n",
    "\n",
    "vanilla_results = {}\n",
    "\n",
    "for model in models:\n",
    "    vanilla_results[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_0_biased_tokens/{model}/{vocab}/typed_querying/{prompt}_result.json\"\n",
    "        # 解析result\n",
    "        with open(results_path) as f:\n",
    "            results = json.load(f)\n",
    "        vanilla_results[model][prompt] = results\n",
    "\n",
    "no_norm_no_rescale = {}\n",
    "for model in models:\n",
    "    no_norm_no_rescale[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_0_biased_tokens/{model}/{vocab}/typed_querying/ablations/{prompt}/no_normal_no_rescale_result.json\"\n",
    "        # 解析result\n",
    "        with open(results_path) as f:\n",
    "            results = json.load(f)\n",
    "        no_norm_no_rescale[model][prompt] = results\n",
    "\n",
    "# 对于每个模型，在每个prompt下，不同数据集给出来vanilla精度，debias精度，debias_no_norm_no_rescale精度的对比\n",
    "\n",
    "import prettytable\n",
    "import pandas as pd\n",
    "for model in models:\n",
    "    column_names = [\"Manual\",\"Manual^d\",\"Manual^d_w/o_norm_rescale\", \"LPAQA\",\"LPAQA^d\",\"LPAQA^d_w/o_norm_rescale\",\"AutoPrompt\",\"AutoPrompt^d\",\"AutoPrompt^d_w/o_norm_rescale\",\"optiprompt\",\"optiprompt^d\",\"optiprompt^d_w/o_norm_rescale\"]\n",
    "        # 行名（索引）\n",
    "    index_names = ['LAMA', 'LAMA-WHU', 'WIKI-UNI']\n",
    "    # result_table.()\n",
    "    df = pd.DataFrame(columns=column_names, index=index_names)\n",
    "    for prompt in prompts:\n",
    "        prefix = prompt if prompt!=\"LAMA\" else \"Manual\"\n",
    "        for index in index_names:\n",
    "            df.loc[index,prefix] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P\"] * 100\n",
    "            df.loc[index,prefix+\"^d\"] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "            df.loc[index,prefix+\"^d_w/o_norm_rescale\"] = next(iter(no_norm_no_rescale[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "    with pd.ExcelWriter('ablation.xlsx', engine='openpyxl', mode='r+', if_sheet_exists=\"replace\") as writer:\n",
    "        df.to_excel(writer, sheet_name=model,float_format=\"%.3f\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前只考虑filter_32_bias_token的情况\n",
    "import json\n",
    "import os\n",
    "# 统计原始结果\n",
    "prompts = [\"LAMA\",\"LPAQA\",\"AutoPrompt\",\"optiprompt\"]\n",
    "models = [\"bert-base-cased\",\"bert-large-cased\",\"roberta-large\"]\n",
    "\n",
    "vanilla_results = {}\n",
    "\n",
    "for model in models:\n",
    "    vanilla_results[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_32_biased_tokens/{model}/{vocab}/typed_querying/{prompt}_result.json\"\n",
    "        # 解析result\n",
    "        with open(results_path) as f:\n",
    "            results = json.load(f)\n",
    "        vanilla_results[model][prompt] = results\n",
    "\n",
    "no_norm_no_rescale = {}\n",
    "for model in models:\n",
    "    no_norm_no_rescale[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_32_biased_tokens/{model}/{vocab}/typed_querying/ablations/{prompt}/no_normal_no_rescale_result.json\"\n",
    "        # 解析result\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path) as f:\n",
    "                results = json.load(f)\n",
    "            no_norm_no_rescale[model][prompt] = results\n",
    "\n",
    "# for model in models:\n",
    "#     no_norm_no_rescale[model] = {}\n",
    "#     for prompt in prompts:\n",
    "#         vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "#         results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_32_biased_tokens/{model}/{vocab}/typed_querying/ablations/{prompt}/no_normal_no_rescale_result.json\"\n",
    "#         # 解析result\n",
    "#         if os.path.exists(results_path):\n",
    "#             with open(results_path) as f:\n",
    "#                 results = json.load(f)\n",
    "#             no_norm_no_rescale[model][prompt] = results\n",
    "\n",
    "\n",
    "\n",
    "# 对于每个模型，在每个prompt下，不同数据集给出来vanilla精度，debias精度，debias_no_norm_no_rescale精度的对比\n",
    "\n",
    "import prettytable\n",
    "import pandas as pd\n",
    "for model in models:\n",
    "    column_names = [\"Manual\",\"Manual^d\",\"Manual^d_w/o_norm_rescale\", \"LPAQA\",\"LPAQA^d\",\"LPAQA^d_w/o_norm_rescale\",\"AutoPrompt\",\"AutoPrompt^d\",\"AutoPrompt^d_w/o_norm_rescale\",\"optiprompt\",\"optiprompt^d\",\"optiprompt^d_w/o_norm_rescale\"]\n",
    "        # 行名（索引）\n",
    "    index_names = ['LAMA', 'LAMA-WHU', 'WIKI-UNI']\n",
    "    # result_table.()\n",
    "    df = pd.DataFrame(columns=column_names, index=index_names)\n",
    "    for prompt in prompts:\n",
    "        prefix = prompt if prompt!=\"LAMA\" else \"Manual\"\n",
    "        for index in index_names:\n",
    "            try:\n",
    "                df.loc[index,prefix] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P\"] * 100\n",
    "                df.loc[index,prefix+\"^d\"] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "                df.loc[index,prefix+\"^d_w/o_norm_rescale\"] = next(iter(no_norm_no_rescale[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "            except:\n",
    "                continue\n",
    "    with pd.ExcelWriter('ablation_filter_32.xlsx', engine='openpyxl', mode='r+', if_sheet_exists=\"replace\") as writer:\n",
    "        df.to_excel(writer, sheet_name=model,float_format=\"%.3f\")\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2a961f21e3910a1829c13a9982b953d485249e8a0f32b2fb196974498b9d8dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('xzy_BiasBench')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
