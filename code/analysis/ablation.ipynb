{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析normalzation操作的必要性和rescale操作的必要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验1，取消norm操作和rescale操作\n",
    "# 当前只考虑filter_0_bias_token的情况\n",
    "import json\n",
    "# 统计原始结果\n",
    "prompts = [\"LAMA\",\"LPAQA\",\"AutoPrompt\",\"optiprompt\"]\n",
    "models = [\"bert-base-cased\",\"bert-large-cased\",\"roberta-large\"]\n",
    "\n",
    "vanilla_results = {}\n",
    "\n",
    "for model in models:\n",
    "    vanilla_results[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_0_biased_tokens/{model}/{vocab}/typed_querying/{prompt}_result.json\"\n",
    "        # 解析result\n",
    "        with open(results_path) as f:\n",
    "            results = json.load(f)\n",
    "        vanilla_results[model][prompt] = results\n",
    "\n",
    "no_norm_no_rescale = {}\n",
    "for model in models:\n",
    "    no_norm_no_rescale[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_0_biased_tokens/{model}/{vocab}/typed_querying/ablations/{prompt}/no_normal_no_rescale_result.json\"\n",
    "        # 解析result\n",
    "        with open(results_path) as f:\n",
    "            results = json.load(f)\n",
    "        no_norm_no_rescale[model][prompt] = results\n",
    "\n",
    "# 对于每个模型，在每个prompt下，不同数据集给出来vanilla精度，debias精度，debias_no_norm_no_rescale精度的对比\n",
    "\n",
    "import prettytable\n",
    "import pandas as pd\n",
    "for model in models:\n",
    "    column_names = [\"Manual\",\"Manual^d\",\"Manual^c\", \"LPAQA\",\"LPAQA^d\",\"LPAQA^c\",\"AutoPrompt\",\"AutoPrompt^d\",\"AutoPrompt^c\",\"optiprompt\",\"optiprompt^d\",\"optiprompt^c\"]\n",
    "        # 行名（索引）\n",
    "    index_names = ['LAMA', 'LAMA-WHU', 'WIKI-UNI']\n",
    "    # result_table.()\n",
    "    df = pd.DataFrame(columns=column_names, index=index_names)\n",
    "    for prompt in prompts:\n",
    "        prefix = prompt if prompt!=\"LAMA\" else \"Manual\"\n",
    "        for index in index_names:\n",
    "            df.loc[index,prefix] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P\"] * 100\n",
    "            df.loc[index,prefix+\"^d\"] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "            df.loc[index,prefix+\"^d_w/o_norm_rescale\"] = next(iter(no_norm_no_rescale[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "    with pd.ExcelWriter('ablation.xlsx', engine='openpyxl', mode='r+', if_sheet_exists=\"replace\") as writer:\n",
    "        df.to_excel(writer, sheet_name=model,float_format=\"%.3f\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前只考虑filter_32_bias_token的情况\n",
    "import json\n",
    "import os\n",
    "# 统计原始结果\n",
    "prompts = [\"LAMA\",\"LPAQA\",\"AutoPrompt\",\"optiprompt\"]\n",
    "models = [\"bert-base-cased\",\"bert-large-cased\",\"roberta-large\"]\n",
    "\n",
    "vanilla_results = {}\n",
    "\n",
    "for model in models:\n",
    "    vanilla_results[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_32_biased_tokens/{model}/{vocab}/typed_querying/{prompt}_result.json\"\n",
    "        # 解析result\n",
    "        with open(results_path) as f:\n",
    "            results = json.load(f)\n",
    "        vanilla_results[model][prompt] = results\n",
    "\n",
    "no_norm_no_rescale = {}\n",
    "for model in models:\n",
    "    no_norm_no_rescale[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_32_biased_tokens/{model}/{vocab}/typed_querying/ablations/{prompt}/no_normal_no_rescale_result.json\"\n",
    "        # 解析result\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path) as f:\n",
    "                results = json.load(f)\n",
    "            no_norm_no_rescale[model][prompt] = results\n",
    "\n",
    "# 对于每个模型，在每个prompt下，不同数据集给出来vanilla精度，debias精度，debias_no_norm_no_rescale精度的对比\n",
    "\n",
    "import prettytable\n",
    "import pandas as pd\n",
    "for model in models:\n",
    "    column_names = [\"Manual\",\"Manual^d\",\"Manual^d_w/o_norm_rescale\", \"LPAQA\",\"LPAQA^d\",\"LPAQA^d_w/o_norm_rescale\",\"AutoPrompt\",\"AutoPrompt^d\",\"AutoPrompt^d_w/o_norm_rescale\",\"optiprompt\",\"optiprompt^d\",\"optiprompt^d_w/o_norm_rescale\"]\n",
    "        # 行名（索引）\n",
    "    index_names = ['LAMA', 'LAMA-WHU', 'WIKI-UNI']\n",
    "    # result_table.()\n",
    "    df = pd.DataFrame(columns=column_names, index=index_names)\n",
    "    for prompt in prompts:\n",
    "        prefix = prompt if prompt!=\"LAMA\" else \"Manual\"\n",
    "        for index in index_names:\n",
    "            try:\n",
    "                df.loc[index,prefix] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P\"] * 100\n",
    "                df.loc[index,prefix+\"^d\"] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "                df.loc[index,prefix+\"^d_w/o_norm_rescale\"] = next(iter(no_norm_no_rescale[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "            except:\n",
    "                continue\n",
    "    with pd.ExcelWriter('ablation_filter_32.xlsx', engine='openpyxl', mode='r+', if_sheet_exists=\"replace\") as writer:\n",
    "        df.to_excel(writer, sheet_name=model,float_format=\"%.3f\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 当前只考虑filter_-1_bias_token的情况 即filter 所有biased token\n",
    "**1. 对比一下calibration和debias的好坏**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-base-cased/common_vocab_cased/typed_querying/LAMA_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-base-cased/common_vocab_cased/typed_querying/LPAQA_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-base-cased/common_vocab_cased/typed_querying/AutoPrompt_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-base-cased/common_vocab_cased/typed_querying/optiprompt_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-large-cased/common_vocab_cased/typed_querying/LAMA_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-large-cased/common_vocab_cased/typed_querying/LPAQA_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-large-cased/common_vocab_cased/typed_querying/AutoPrompt_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/bert-large-cased/common_vocab_cased/typed_querying/optiprompt_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/roberta-large/common_vocab_cased_be_ro_al/typed_querying/LAMA_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/roberta-large/common_vocab_cased_be_ro_al/typed_querying/LPAQA_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/roberta-large/common_vocab_cased_be_ro_al/typed_querying/AutoPrompt_result_do_debias.json\n",
      "/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/roberta-large/common_vocab_cased_be_ro_al/typed_querying/optiprompt_result_do_debias.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# 统计原始结果\n",
    "prompts = [\"LAMA\",\"LPAQA\",\"AutoPrompt\",\"optiprompt\"]\n",
    "models = [\"bert-base-cased\",\"bert-large-cased\",\"roberta-large\"]\n",
    "\n",
    "vanilla_results = {}\n",
    "\n",
    "for model in models:\n",
    "    vanilla_results[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/{model}/{vocab}/typed_querying/{prompt}_result.json\"\n",
    "        # 解析result\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path) as f:\n",
    "                results = json.load(f)\n",
    "            vanilla_results[model][prompt] = results\n",
    "\n",
    "calibration = {}\n",
    "for model in models:\n",
    "    calibration[model] = {}\n",
    "    for prompt in prompts:\n",
    "        vocab = \"common_vocab_cased\" if model != \"roberta-large\" else \"common_vocab_cased_be_ro_al\"\n",
    "        results_path = f\"/mnt/code/users/xuziyang/PromptBias/results/filter_out_-1_biased_tokens/{model}/{vocab}/typed_querying/{prompt}_result_do_debias.json\"\n",
    "        # 解析result\n",
    "        print(results_path)\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path) as f:\n",
    "                results = json.load(f)\n",
    "            calibration[model][prompt] = results\n",
    "\n",
    "import pandas as pd\n",
    "for model in models:\n",
    "    column_names = [\"Manual\",\"Manual^d\",\"Manual^c\", \"LPAQA\",\"LPAQA^d\",\"LPAQA^c\",\"AutoPrompt\",\"AutoPrompt^d\",\"AutoPrompt^c\",\"optiprompt\",\"optiprompt^d\",\"optiprompt^c\"]\n",
    "        # 行名（索引）\n",
    "    index_names = ['LAMA', 'LAMA-WHU', 'WIKI-UNI']\n",
    "    # result_table.()\n",
    "    df = pd.DataFrame(columns=column_names, index=index_names)\n",
    "    for prompt in prompts:\n",
    "        prefix = prompt if prompt!=\"LAMA\" else \"Manual\"\n",
    "        for index in index_names:\n",
    "            try:\n",
    "                df.loc[index,prefix] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P\"] * 100\n",
    "                df.loc[index,prefix+\"^d\"] = next(iter(vanilla_results[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "                df.loc[index,prefix+\"^c\"] = next(iter(calibration[model][prompt][model][index].values()))[\"P_d\"] * 100\n",
    "            except:\n",
    "                continue\n",
    "    with pd.ExcelWriter('ablation_filter_all.xlsx', engine='openpyxl', mode='r+', if_sheet_exists=\"replace\") as writer:\n",
    "        df.to_excel(writer, sheet_name=model,float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-cased': {'LAMA': {'bert-base-cased': {'LAMA': {'LAMA': {'P': 0.24311804878048782,\n",
       "      'P_d': 0.32221780487804874,\n",
       "      'KL': 2.2255643902439024,\n",
       "      'KL_d': 4.757011463414634,\n",
       "      'TT_CE': 0.734726747727366,\n",
       "      'TT_CE_d': 0.37681545668190275,\n",
       "      'FF_E': 3.6916700830532125,\n",
       "      'FF_E_d': 4.762948847097998}},\n",
       "    'WIKI-UNI': {'LAMA': {'P': 0.15013609756097562,\n",
       "      'P_d': 0.24013439024390243,\n",
       "      'KL': 1.9063831707317074,\n",
       "      'KL_d': 4.764495853658537,\n",
       "      'TT_CE': 0.8799525159453672,\n",
       "      'TT_CE_d': 0.45326530460714076,\n",
       "      'FF_E': 3.982441284737286,\n",
       "      'FF_E_d': 5.290178325713647}},\n",
       "    'LAMA-WHU': {'LAMA': {'P': 0.14006658536585365,\n",
       "      'P_d': 0.2037792682926829,\n",
       "      'KL': 1.8173987804878053,\n",
       "      'KL_d': 4.521883658536586,\n",
       "      'TT_CE': 0.8648849356354857,\n",
       "      'TT_CE_d': 0.5479195677101689,\n",
       "      'FF_E': 3.6488705528968954,\n",
       "      'FF_E_d': 4.737847146990278}}}},\n",
       "  'LPAQA': {'bert-base-cased': {'LAMA': {'LPAQA': {'P': 0.223060243902439,\n",
       "      'P_d': 0.31966731707317075,\n",
       "      'KL': 2.049378780487805,\n",
       "      'KL_d': 4.714916585365853,\n",
       "      'TT_CE': 0.6903773377357153,\n",
       "      'TT_CE_d': 0.35173481010142993,\n",
       "      'FF_E': 3.543888115947956,\n",
       "      'FF_E_d': 4.704784130456781}},\n",
       "    'WIKI-UNI': {'LPAQA': {'P': 0.14603682926829267,\n",
       "      'P_d': 0.24086926829268293,\n",
       "      'KL': 1.7689617073170731,\n",
       "      'KL_d': 4.605671463414634,\n",
       "      'TT_CE': 0.9497036635812375,\n",
       "      'TT_CE_d': 0.4833925294021202,\n",
       "      'FF_E': 3.854403721916567,\n",
       "      'FF_E_d': 5.308069980566726}},\n",
       "    'LAMA-WHU': {'LPAQA': {'P': 0.12921731707317075,\n",
       "      'P_d': 0.21019073170731709,\n",
       "      'KL': 1.7082780487804878,\n",
       "      'KL_d': 4.462038536585366,\n",
       "      'TT_CE': 0.7819421725815763,\n",
       "      'TT_CE_d': 0.5033878757871125,\n",
       "      'FF_E': 3.510425223636992,\n",
       "      'FF_E_d': 4.680920130901545}}}},\n",
       "  'AutoPrompt': {'bert-base-cased': {'LAMA': {'AutoPrompt': {'P': 0.26290170731707313,\n",
       "      'P_d': 0.3216917073170732,\n",
       "      'KL': 2.4171317073170733,\n",
       "      'KL_d': 5.431360243902439,\n",
       "      'TT_CE': 0.5126203735142775,\n",
       "      'TT_CE_d': 0.2885749821702373,\n",
       "      'FF_E': 3.1529233730415194,\n",
       "      'FF_E_d': 4.449146827939715}},\n",
       "    'WIKI-UNI': {'AutoPrompt': {'P': 0.16718121951219514,\n",
       "      'P_d': 0.24908463414634147,\n",
       "      'KL': 2.0263619512195126,\n",
       "      'KL_d': 5.4376258536585365,\n",
       "      'TT_CE': 0.6577901916183374,\n",
       "      'TT_CE_d': 0.3498904095392009,\n",
       "      'FF_E': 3.371713732507214,\n",
       "      'FF_E_d': 4.907078803383179}},\n",
       "    'LAMA-WHU': {'AutoPrompt': {'P': 0.13571634146341463,\n",
       "      'P_d': 0.20045731707317074,\n",
       "      'KL': 1.8228239024390243,\n",
       "      'KL_d': 5.19818,\n",
       "      'TT_CE': 0.6402046392406011,\n",
       "      'TT_CE_d': 0.4540919530994867,\n",
       "      'FF_E': 3.119243163689473,\n",
       "      'FF_E_d': 4.422013717455437}}}}},\n",
       " 'bert-large-cased': {},\n",
       " 'roberta-large': {}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2a961f21e3910a1829c13a9982b953d485249e8a0f32b2fb196974498b9d8dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('xzy_BiasBench')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
